{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport numpy as np\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport copy\nfrom copy import deepcopy as dp\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom scipy.spatial import ConvexHull\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import transforms\nimport torchvision.models as models\n\nimport pickle\nfrom pickle import dump, load\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nexperiment_name=\"Resnet_deepinsight\"\nmodel_output_folder = f\"./{experiment_name}\"\nos.makedirs(model_output_folder, exist_ok=True)\n\ndef g_table(list1):\n    table_dic = {}\n    for i in list1:\n        if i not in table_dic.keys():\n            table_dic[i] = 1\n        else:\n            table_dic[i] += 1\n    return(table_dic)\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet50(pretrained = True)\nmodel.load_state_dict(torch.load('../input/resnet50/resnet50.pth'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = [0]\ninput_dir = '../input/lish-moa/'\n\nsc_dic = {}\nfeat_dic = {}\ntrain_features = pd.read_csv(input_dir+'train_features.csv')\ntrain_targets_scored = pd.read_csv(input_dir+'train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv(input_dir+'train_targets_nonscored.csv')\ntest_features = pd.read_csv(input_dir+'test_features.csv')\nsample_submission = pd.read_csv(input_dir+'sample_submission.csv')\ntrain_drug = pd.read_csv(input_dir+'train_drug.csv')\n\ntarget_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()\ntarget_nonsc_cols = train_targets_nonscored.drop('sig_id', axis=1).columns.values.tolist()\n\n######## non-score ########\nnonctr_id = train_features.loc[:,'sig_id'].tolist()\ntmp_con1 = [i in nonctr_id for i in train_targets_scored['sig_id']]\nmat_cor = pd.DataFrame(np.corrcoef(train_targets_scored.drop('sig_id',axis = 1)[tmp_con1].T,\n                      train_targets_nonscored.drop('sig_id',axis = 1)[tmp_con1].T))\nmat_cor2 = mat_cor.iloc[(train_targets_scored.shape[1]-1):,0:train_targets_scored.shape[1]-1]\nmat_cor2.index = target_nonsc_cols\nmat_cor2.columns = target_cols\nmat_cor2 = mat_cor2.dropna()\nmat_cor2_max = mat_cor2.abs().max(axis = 1)\n\nq_n_cut = 0.9\ntarget_nonsc_cols2 = mat_cor2_max[mat_cor2_max > np.quantile(mat_cor2_max,q_n_cut)].index.tolist()\nprint(len(target_nonsc_cols2))\n\nGENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]\nfeat_dic['gene'] = GENES\nfeat_dic['cell'] = CELLS\ntrain = train_features.merge(train_targets_scored, on='sig_id')\ntrain = train.merge(train_targets_nonscored[['sig_id']+target_nonsc_cols2], on='sig_id')\n\ntarget = train[['sig_id']+target_cols]\ntarget_ns = train[['sig_id']+target_nonsc_cols2]\n\n# train0 = train.drop('cp_type', axis=1)\n# test = test.drop('cp_type', axis=1)\ntrain0 = train\ntest = test_features\n\nfor df in [train0, test]:\n    df['cp_type'] = df['cp_type'].map({'ctl_vehicle': 0, 'trt_cp': 1})\n    df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n    df['cp_time'] = df['cp_time'].map({24: 0, 48: 0.5, 72: 1})\n\ntarget_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n\n# drug ids\ntar_sig = target['sig_id'].tolist()\ntrain_drug = train_drug.loc[[i in tar_sig for i in train_drug['sig_id']]]\ntarget = target.merge(train_drug, on='sig_id', how='left') \n\n# LOCATE DRUGS\nvc = train_drug.drug_id.value_counts()\nvc1 = vc.loc[vc <= 19].index\nvc2 = vc.loc[vc > 19].index\n\nfeature_cols = []\nfor key_i in feat_dic.keys():\n    value_i = feat_dic[key_i]\n    print(key_i,len(value_i))\n    feature_cols += value_i\nlen(feature_cols)\nfeature_cols0 = dp(feature_cols)\n    \noof = np.zeros((len(train), len(target_cols)))\npredictions = np.zeros((len(test), len(target_cols)))\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Averaging on multiple SEEDS\nfor seed in SEED:\n\n    seed_everything(seed=seed)\n    folds = train0.copy()\n    feature_cols = dp(feature_cols0)\n    \n    # kfold - leave drug out\n    target2 = target.copy()\n    dct1 = {}; dct2 = {}\n    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n    tmp = target2.groupby('drug_id')[target_cols].mean().loc[vc1]\n    tmp_idx = tmp.index.tolist()\n    tmp_idx.sort()\n    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n    tmp = tmp.loc[tmp_idx2]\n    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n        dd = {k:fold for k in tmp.index[idxV].values}\n        dct1.update(dd)\n\n    # STRATIFY DRUGS MORE THAN 19X\n    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n    tmp = target2.loc[target2.drug_id.isin(vc2)].reset_index(drop = True)\n    tmp_idx = tmp.index.tolist()\n    tmp_idx.sort()\n    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n    tmp = tmp.loc[tmp_idx2]\n    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n        dd = {k:fold for k in tmp.sig_id[idxV].values}\n        dct2.update(dd)\n\n    target2['kfold'] = target2.drug_id.map(dct1)\n    target2.loc[target2.kfold.isna(),'kfold'] = target2.loc[target2.kfold.isna(),'sig_id'].map(dct2)\n    target2.kfold = target2.kfold.astype(int)\n\n    folds['kfold'] = target2['kfold'].copy()\n\n    train = folds.copy()\n    test_ = test.copy()\n\n    # HyperParameters\n    DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n    EPOCHS = 15\n    BATCH_SIZE = 48\n    LEARNING_RATE = 1e-3\n    WEIGHT_DECAY = 1e-5\n    NFOLDS = 5\n    EARLY_STOPPING_STEPS = 10\n    EARLY_STOP = False\n\n    n_comp1 = 50\n    n_comp2 = 15\n\n    num_features=len(feature_cols) + n_comp1 + n_comp2\n    num_targets=len(target_cols)\n    num_targets_0=len(target_nonsc_cols2)\n    hidden_size=4096\n\n    tar_freq = np.array([np.min(list(g_table(train[target_cols].iloc[:,i]).values())) for i in range(len(target_cols))])\n    tar_weight0 = np.array([np.log(i+100) for i in tar_freq])\n    tar_weight0_min = dp(np.min(tar_weight0))\n    tar_weight = tar_weight0_min/tar_weight0\n    pos_weight = torch.tensor(tar_weight).to(DEVICE)\n    from torch.nn.modules.loss import _WeightedLoss\n    class SmoothBCEwLogits(_WeightedLoss):\n        def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n            super().__init__(weight=weight, reduction=reduction)\n            self.smoothing = smoothing\n            self.weight = weight\n            self.reduction = reduction\n\n        @staticmethod\n        def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n            assert 0 <= smoothing < 1\n            with torch.no_grad():\n                targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n            return targets\n\n        def forward(self, inputs, targets):\n            targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n                self.smoothing)\n            loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n\n            if  self.reduction == 'sum':\n                loss = loss.sum()\n            elif  self.reduction == 'mean':\n                loss = loss.mean()\n\n            return loss\n        \n    # Alicia - DeepInsight\n    class LogScaler:\n        \"\"\"Log normalize and scale data\n\n        Log normalization and scaling procedure as described as norm-2 in the\n        DeepInsight paper supplementary information.\n\n        Note: The dimensions of input matrix is (N samples, d features)\n        \"\"\"\n        def __init__(self):\n            self._min0 = None\n            self._max = None\n\n        \"\"\"\n        Use this as a preprocessing step in inference mode.\n        \"\"\"\n        def fit(self, X, y=None):\n            # Min. of training set per feature\n            self._min0 = X.min(axis=0)\n\n            # Log normalized X by log(X + _min0 + 1)\n            X_norm = np.log(X + np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) + 1).clip(min=0, max=None)\n\n            # Global max. of training set from X_norm\n            self._max = X_norm.max()\n\n        \"\"\"\n        For training set only.\n        \"\"\"\n        def fit_transform(self, X, y=None):\n            # Min. of training set per feature\n            self._min0 = X.min(axis=0)\n\n            # Log normalized X by log(X + _min0 + 1)\n            X_norm = np.log(X + np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) + 1).clip(min=0, max=None)\n\n            # Global max. of training set from X_norm\n            self._max = X_norm.max()\n\n            # Normalized again by global max. of training set\n            return (X_norm / self._max).clip(0, 1)\n\n        \"\"\"\n        For validation and test set only.\n        \"\"\"\n        def transform(self, X, y=None):\n            # Adjust min. of each feature of X by _min0\n            for i in range(X.shape[1]):\n                X[:, i] = X[:, i].clip(min=self._min0[i], max=None)\n\n            # Log normalized X by log(X + _min0 + 1)\n            X_norm = np.log(\n                X +\n                np.repeat(np.abs(self._min0)[np.newaxis, :], X.shape[0], axis=0) +\n                1).clip(min=0, max=None)\n\n            # Normalized again by global max. of training set\n            return (X_norm / self._max).clip(0, 1)\n    \n    class DeepInsightTransformer:\n        \"\"\"Transform features to an image matrix using dimensionality reduction\n\n        This class takes in data normalized between 0 and 1 and converts it to a\n        CNN compatible 'image' matrix\n\n        \"\"\"\n        def __init__(self,\n                     feature_extractor='tsne',\n                     perplexity=30,\n                     pixels=100,\n                     random_state=None,\n                     n_jobs=None):\n            \"\"\"Generate an ImageTransformer instance\n\n            Args:\n                feature_extractor: string of value ('tsne', 'pca', 'kpca') or a\n                    class instance with method `fit_transform` that returns a\n                    2-dimensional array of extracted features.\n                pixels: int (square matrix) or tuple of ints (height, width) that\n                    defines the size of the image matrix.\n                random_state: int or RandomState. Determines the random number\n                    generator, if present, of a string defined feature_extractor.\n                n_jobs: The number of parallel jobs to run for a string defined\n                    feature_extractor.\n            \"\"\"\n            self.random_state = random_state\n            self.n_jobs = n_jobs\n\n            if isinstance(feature_extractor, str):\n                fe = feature_extractor.casefold()\n                if fe == 'tsne_exact'.casefold():\n                    fe = TSNE(n_components=2,\n                              metric='cosine',\n                              perplexity=perplexity,\n                              n_iter=1000,\n                              method='exact',\n                              random_state=self.random_state,\n                              n_jobs=self.n_jobs)\n                elif fe == 'tsne'.casefold():\n                    fe = TSNE(n_components=2,\n                              metric='cosine',\n                              perplexity=perplexity,\n                              n_iter=1000,\n                              method='barnes_hut',\n                              random_state=self.random_state,\n                              n_jobs=self.n_jobs)\n                elif fe == 'pca'.casefold():\n                    fe = PCA(n_components=2, random_state=self.random_state)\n                elif fe == 'kpca'.casefold():\n                    fe = KernelPCA(n_components=2,\n                                   kernel='rbf',\n                                   random_state=self.random_state,\n                                   n_jobs=self.n_jobs)\n                else:\n                    raise ValueError((\"Feature extraction method '{}' not accepted\"\n                                      ).format(feature_extractor))\n                self._fe = fe\n            elif hasattr(feature_extractor, 'fit_transform') and \\\n                    inspect.ismethod(feature_extractor.fit_transform):\n                self._fe = feature_extractor\n            else:\n                raise TypeError('Parameter feature_extractor is not a '\n                                'string nor has method \"fit_transform\"')\n\n            if isinstance(pixels, int):\n                pixels = (pixels, pixels)\n\n            # The resolution of transformed image\n            self._pixels = pixels\n            self._xrot = None\n\n        def fit(self, X, y=None, plot=False):\n            \"\"\"Train the image transformer from the training set (X)\n\n            Args:\n                X: {array-like, sparse matrix} of shape (n_samples, n_features)\n                y: Ignored. Present for continuity with scikit-learn\n                plot: boolean of whether to produce a scatter plot showing the\n                    feature reduction, hull points, and minimum bounding rectangle\n\n            Returns:\n                self: object\n            \"\"\"\n            # Transpose to get (n_features, n_samples)\n            X = X.T\n\n            # Perform dimensionality reduction\n            x_new = self._fe.fit_transform(X)\n\n            # Get the convex hull for the points\n            chvertices = ConvexHull(x_new).vertices\n            hull_points = x_new[chvertices]\n\n            # Determine the minimum bounding rectangle\n            mbr, mbr_rot = self._minimum_bounding_rectangle(hull_points)\n\n            # Rotate the matrix\n            # Save the rotated matrix in case user wants to change the pixel size\n            self._xrot = np.dot(mbr_rot, x_new.T).T\n\n            # Determine feature coordinates based on pixel dimension\n            self._calculate_coords()\n\n            # plot rotation diagram if requested\n            if plot is True:\n                # Create subplots\n                fig, ax = plt.subplots(1, 1, figsize=(10, 7), squeeze=False)\n                ax[0, 0].scatter(x_new[:, 0],\n                                 x_new[:, 1],\n                                 cmap=plt.cm.get_cmap(\"jet\", 10),\n                                 marker=\"x\",\n                                 alpha=1.0)\n                ax[0, 0].fill(x_new[chvertices, 0],\n                              x_new[chvertices, 1],\n                              edgecolor='r',\n                              fill=False)\n                ax[0, 0].fill(mbr[:, 0], mbr[:, 1], edgecolor='g', fill=False)\n                plt.gca().set_aspect('equal', adjustable='box')\n                plt.show()\n            return self\n\n        @property\n        def pixels(self):\n            \"\"\"The image matrix dimensions\n\n            Returns:\n                tuple: the image matrix dimensions (height, width)\n\n            \"\"\"\n            return self._pixels\n\n        @pixels.setter\n        def pixels(self, pixels):\n            \"\"\"Set the image matrix dimension\n\n            Args:\n                pixels: int or tuple with the dimensions (height, width)\n                of the image matrix\n\n            \"\"\"\n            if isinstance(pixels, int):\n                pixels = (pixels, pixels)\n            self._pixels = pixels\n            # recalculate coordinates if already fit\n            if hasattr(self, '_coords'):\n                self._calculate_coords()\n\n        def _calculate_coords(self):\n            \"\"\"Calculate the matrix coordinates of each feature based on the\n            pixel dimensions.\n            \"\"\"\n            ax0_coord = np.digitize(self._xrot[:, 0],\n                                    bins=np.linspace(min(self._xrot[:, 0]),\n                                                     max(self._xrot[:, 0]),\n                                                     self._pixels[0])) - 1\n            ax1_coord = np.digitize(self._xrot[:, 1],\n                                    bins=np.linspace(min(self._xrot[:, 1]),\n                                                     max(self._xrot[:, 1]),\n                                                     self._pixels[1])) - 1\n            self._coords = np.stack((ax0_coord, ax1_coord))\n\n        def transform(self, X, empty_value=0):\n            \"\"\"Transform the input matrix into image matrices\n\n            Args:\n                X: {array-like, sparse matrix} of shape (n_samples, n_features)\n                    where n_features matches the training set.\n                empty_value: numeric value to fill elements where no features are\n                    mapped. Default = 0 (although it was 1 in the paper).\n\n            Returns:\n                A list of n_samples numpy matrices of dimensions set by\n                the pixel parameter\n            \"\"\"\n            # Group by location (x1, y1) of each feature\n            # Tranpose to get (n_features, n_samples)\n            img_coords = pd.DataFrame(np.vstack(\n                (self._coords, X.clip(0, 1))).T).groupby(\n                    [0, 1],  # (x1, y1)\n                    as_index=False).mean()\n\n            img_matrices = []\n            blank_mat = np.zeros(self._pixels)\n            if empty_value != 0:\n                blank_mat[:] = empty_value\n            for z in range(2, img_coords.shape[1]):\n                img_matrix = blank_mat.copy()\n                img_matrix[img_coords[0].astype(int),\n                           img_coords[1].astype(int)] = img_coords[z]\n                img_matrices.append(img_matrix)\n            \n            img_matrices = np.array([self._mat_to_rgb(m) for m in img_matrices])\n                \n            return img_matrices\n        \n        def transform_3d(self, X, empty_value=0):\n            \"\"\"Transform the input matrix into image matrices\n\n            Args:\n                X: {array-like, sparse matrix} of shape (n_samples, n_features)\n                    where n_features matches the training set.\n                empty_value: numeric value to fill elements where no features are\n                    mapped. Default = 0 (although it was 1 in the paper).\n\n            Returns:\n                A list of n_samples numpy matrices of dimensions set by\n                the pixel parameter\n            \"\"\"\n\n            # Group by location (x1, y1) of each feature\n            # Tranpose to get (n_features, n_samples)\n            img_coords = pd.DataFrame(np.vstack(\n                (self._coords, X.clip(0, 1))).T).groupby(\n                    [0, 1],  # (x1, y1)\n                    as_index=False)\n            avg_img_coords = img_coords.mean()\n            min_img_coords = img_coords.min()\n            max_img_coords = img_coords.max()\n\n            img_matrices = []\n            blank_mat = np.zeros((3, self._pixels[0], self._pixels[1]))\n            if empty_value != 0:\n                blank_mat[:, :, :] = empty_value\n            for z in range(2, avg_img_coords.shape[1]):\n                img_matrix = blank_mat.copy()\n                img_matrix[0, avg_img_coords[0].astype(int),\n                           avg_img_coords[1].astype(int)] = avg_img_coords[z]\n                img_matrix[1, min_img_coords[0].astype(int),\n                           min_img_coords[1].astype(int)] = min_img_coords[z]\n                img_matrix[2, max_img_coords[0].astype(int),\n                           max_img_coords[1].astype(int)] = max_img_coords[z]\n                img_matrices.append(img_matrix)\n\n            return img_matrices\n\n        def fit_transform(self, X, empty_value=0):\n            \"\"\"Train the image transformer from the training set (X) and return\n            the transformed data.\n\n            Args:\n                X: {array-like, sparse matrix} of shape (n_samples, n_features)\n                empty_value: numeric value to fill elements where no features are\n                    mapped. Default = 0 (although it was 1 in the paper).\n\n            Returns:\n                A list of n_samples numpy matrices of dimensions set by\n                the pixel parameter\n            \"\"\"\n            self.fit(X)\n            return self.transform(X, empty_value=empty_value)\n        \n        def fit_transform_3d(self, X, empty_value=0):\n            \"\"\"Train the image transformer from the training set (X) and return\n            the transformed data.\n\n            Args:\n                X: {array-like, sparse matrix} of shape (n_samples, n_features)\n                empty_value: numeric value to fill elements where no features are\n                    mapped. Default = 0 (although it was 1 in the paper).\n\n            Returns:\n                A list of n_samples numpy matrices of dimensions set by\n                the pixel parameter\n            \"\"\"\n            self.fit(X)\n            return self.transform_3d(X, empty_value=empty_value)\n\n        def feature_density_matrix(self):\n            \"\"\"Generate image matrix with feature counts per pixel\n\n            Returns:\n                img_matrix (ndarray): matrix with feature counts per pixel\n            \"\"\"\n            fdmat = np.zeros(self._pixels)\n            # Group by location (x1, y1) of each feature\n            # Tranpose to get (n_features, n_samples)\n            coord_cnt = (\n                pd.DataFrame(self._coords.T).assign(count=1).groupby(\n                    [0, 1],  # (x1, y1)\n                    as_index=False).count())\n            fdmat[coord_cnt[0].astype(int),\n                  coord_cnt[1].astype(int)] = coord_cnt['count']\n            return fdmat\n\n        @staticmethod\n        def _minimum_bounding_rectangle(hull_points):\n            \"\"\"Find the smallest bounding rectangle for a set of points.\n\n            Modified from JesseBuesking at https://stackoverflow.com/a/33619018\n            Returns a set of points representing the corners of the bounding box.\n\n            Args:\n                hull_points : an nx2 matrix of hull coordinates\n\n            Returns:\n                (tuple): tuple containing\n                    coords (ndarray): coordinates of the corners of the rectangle\n                    rotmat (ndarray): rotation matrix to align edges of rectangle\n                        to x and y\n            \"\"\"\n\n            pi2 = np.pi / 2.\n\n            # Calculate edge angles\n            edges = hull_points[1:] - hull_points[:-1]\n            angles = np.arctan2(edges[:, 1], edges[:, 0])\n            angles = np.abs(np.mod(angles, pi2))\n            angles = np.unique(angles)\n\n            # Find rotation matrices\n            rotations = np.vstack([\n                np.cos(angles),\n                np.cos(angles - pi2),\n                np.cos(angles + pi2),\n                np.cos(angles)\n            ]).T\n            rotations = rotations.reshape((-1, 2, 2))\n\n            # Apply rotations to the hull\n            rot_points = np.dot(rotations, hull_points.T)\n\n            # Find the bounding points\n            min_x = np.nanmin(rot_points[:, 0], axis=1)\n            max_x = np.nanmax(rot_points[:, 0], axis=1)\n            min_y = np.nanmin(rot_points[:, 1], axis=1)\n            max_y = np.nanmax(rot_points[:, 1], axis=1)\n\n            # Find the box with the best area\n            areas = (max_x - min_x) * (max_y - min_y)\n            best_idx = np.argmin(areas)\n\n            # Return the best box\n            x1 = max_x[best_idx]\n            x2 = min_x[best_idx]\n            y1 = max_y[best_idx]\n            y2 = min_y[best_idx]\n            rotmat = rotations[best_idx]\n\n            # Generate coordinates\n            coords = np.zeros((4, 2))\n            coords[0] = np.dot([x1, y2], rotmat)\n            coords[1] = np.dot([x2, y2], rotmat)\n            coords[2] = np.dot([x2, y1], rotmat)\n            coords[3] = np.dot([x1, y1], rotmat)\n\n            return coords, rotmat\n        \n        @staticmethod\n        def _mat_to_rgb(mat):\n            \"\"\"Convert image matrix to numpy rgb format\n            Args:\n                mat: {array-like} (M, N)\n            Returns:\n                An numpy.ndarry (M, N, 3) with orignal values repeated across\n                RGB channels.\n            \"\"\"\n            return np.repeat(mat[:, :, np.newaxis], 3, axis=2)\n\n    class TrainDataset(torch.utils.data.Dataset):\n        def __init__(self, features, labels, transformer):\n            self.features = features\n            self.labels = labels\n            self.transformer = transformer\n\n        def __getitem__(self, index):\n            normalized = self.features[index, :]\n            normalized = np.expand_dims(normalized, axis=0)\n\n            # Note: we are setting empty_value=1 to follow the setup in the paper\n            image = self.transformer.transform(normalized, empty_value=1)[0]\n            \n            preprocess = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ])\n        \n            return {\"x\": preprocess(image).type(torch.float), \"y\": torch.tensor(self.labels[index, :],dtype=torch.float)}\n        \n        \n        def __len__(self):\n            return self.features.shape[0]\n\n\n    class TestDataset(torch.utils.data.Dataset):\n        def __init__(self, features,transformer):\n            self.features = features\n            self.transformer = transformer\n\n        def __getitem__(self, index):\n            normalized = self.features[index, :]\n            normalized = np.expand_dims(normalized, axis=0)\n\n            # Note: we are setting empty_value=1 to follow the setup in the paper\n            image = self.transformer.transform(normalized, empty_value=1)[0]\n            \n            preprocess = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ])\n            return  {\"x\": preprocess(image).type(torch.float), \"y\": -1}\n\n        def __len__(self):\n            return self.features.shape[0]\n        \n\n\n    def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n        model.train()\n        final_loss = 0\n\n        for data in dataloader:\n            optimizer.zero_grad()\n            inputs, targets = data['x'].to(device), data['y'].to(device)\n            outputs = model(inputs)\n            loss = loss_fn(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            final_loss += loss.item()\n\n        final_loss /= len(dataloader)\n\n        return final_loss\n\n\n    def valid_fn(model, loss_fn, dataloader, device):\n        model.eval()\n        final_loss = 0\n        valid_preds = []\n\n        for data in dataloader:\n            inputs, targets = data['x'].to(device), data['y'].to(device)\n            outputs = model(inputs)\n            loss = loss_fn(outputs, targets)\n\n            final_loss += loss.item()\n            valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n\n        final_loss /= len(dataloader)\n        valid_preds = np.concatenate(valid_preds)\n\n        return final_loss, valid_preds\n\n    def inference_fn(model, dataloader, device):\n        model.eval()\n        preds = []\n\n        for data in dataloader:\n            inputs = data['x'].to(device)\n            with torch.no_grad():\n                outputs = model(inputs)\n\n            preds.append(outputs.sigmoid().detach().cpu().numpy())\n\n        preds = np.concatenate(preds)\n\n        return preds\n\n   \n\n    def run_training(fold, seed):\n\n        seed_everything(seed)\n\n        trn_idx = train[train['kfold'] != fold].index\n        val_idx = train[train['kfold'] == fold].index\n\n        train_df = train[train['kfold'] != fold].reset_index(drop=True).copy()\n        valid_df = train[train['kfold'] == fold].reset_index(drop=True).copy()\n\n        x_train, y_train,y_train_ns = train_df[feature_cols].values, train_df[target_cols].values,train_df[target_nonsc_cols2].values\n        x_valid, y_valid,y_valid_ns  =  valid_df[feature_cols].values, valid_df[target_cols].values,valid_df[target_nonsc_cols2].values\n        x_test = test_[feature_cols].values\n\n        #------------ norm --------------\n#         col_num = list(set(feat_dic['gene'] + feat_dic['cell']) & set(feature_cols))\n#         col_num.sort()\n#         x_train[col_num],ss = norm_fit(x_train[col_num],True,'quan')\n#         x_valid[col_num]    = norm_tra(x_valid[col_num],ss)\n#         x_test[col_num]     = norm_tra(x_test[col_num],ss)\n        \n\n        #------------ pca --------------\n#         def pca_pre(tr,va,te,\n#                     n_comp,feat_raw,feat_new):\n#             pca = PCA(n_components=n_comp, random_state=42)\n#             tr2 = pd.DataFrame(pca.fit_transform(tr[feat_raw]),columns=feat_new)\n#             va2 = pd.DataFrame(pca.transform(va[feat_raw]),columns=feat_new)\n#             te2 = pd.DataFrame(pca.transform(te[feat_raw]),columns=feat_new)\n#             return(tr2,va2,te2)\n\n\n#         pca_feat_g = [f'pca_G-{i}' for i in range(n_comp1)]\n#         feat_dic['pca_g'] = pca_feat_g\n#         x_tr_g_pca,x_va_g_pca,x_te_g_pca = pca_pre(x_train,x_valid,x_test,\n#                                                    n_comp1,feat_dic['gene'],pca_feat_g)\n#         x_train = pd.concat([x_train,x_tr_g_pca],axis = 1)\n#         x_valid = pd.concat([x_valid,x_va_g_pca],axis = 1)\n#         x_test  = pd.concat([x_test,x_te_g_pca],axis = 1)\n\n#         pca_feat_g = [f'pca_C-{i}' for i in range(n_comp2)]\n#         feat_dic['pca_c'] = pca_feat_g\n#         x_tr_c_pca,x_va_c_pca,x_te_c_pca = pca_pre(x_train,x_valid,x_test,\n#                                                    n_comp2,feat_dic['cell'],pca_feat_g)\n#         x_train = pd.concat([x_train,x_tr_c_pca],axis = 1)\n#         x_valid = pd.concat([x_valid,x_va_c_pca],axis = 1)\n#         x_test  = pd.concat([x_test,x_te_c_pca], axis = 1)\n\n#         x_train,x_valid,x_test = x_train.values,x_valid.values,x_test.values\n\n        def save_pickle(obj, model_output_folder, seed, fold_i, name):\n            dump(obj, open(f\"{model_output_folder}/seed{seed}_fold{fold_i}_{name}.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)\n\n        \n        # LogScaler (Norm-2 Normalization)\n        print(\"Running norm-2 normalization ......\")\n        scaler = LogScaler()\n        x_train = scaler.fit_transform(x_train)\n        x_valid = scaler.transform(x_valid)\n        x_test = scaler.transform(x_test)\n        \n        save_pickle(scaler, model_output_folder, seed, fold, \"log-scaler\")\n        \n        \n        # Extract DeepInsight Feature Map\n        print(\"Extracting feature map ......\")\n        transformer = DeepInsightTransformer(feature_extractor='tsne_exact',\n                                pixels=224,\n                                perplexity=5,\n                                random_state=seed,\n                                n_jobs=-1)\n        \n        transformer.fit(x_train)\n        \n#         \n        \n        save_pickle(transformer, model_output_folder, seed, fold, \"deepinsight-transform\")\n\n       \n        train_dataset = TrainDataset(x_train, y_train_ns, transformer)\n        valid_dataset = TrainDataset(x_valid, y_valid_ns, transformer)\n        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, len(target_nonsc_cols2))\n        model.to(DEVICE)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, \n                                                  max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n\n        loss_tr = nn.BCEWithLogitsLoss()   #SmoothBCEwLogits(smoothing = 0.001)\n        loss_va = nn.BCEWithLogitsLoss()    \n\n        early_stopping_steps = EARLY_STOPPING_STEPS\n        early_step = 0\n\n        for epoch in range(1):\n            train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n            valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n            print(f\"FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, len(target_cols))\n        model.to(DEVICE)\n\n        train_dataset = TrainDataset(x_train, y_train, transformer)\n        valid_dataset = TrainDataset(x_valid, y_valid, transformer)\n        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n                                                  max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n\n        loss_tr = SmoothBCEwLogits(smoothing = 0.001)\n        loss_va = nn.BCEWithLogitsLoss()    \n\n        early_stopping_steps = EARLY_STOPPING_STEPS\n        early_step = 0\n\n        oof = np.zeros((len(train), len(target_cols)))\n        best_loss = np.inf\n\n        mod_name = f\"FOLD_mod11_{seed}_{fold}_.pth\"\n        \n        for epoch in range(EPOCHS):\n            train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n            valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n            print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n\n            if valid_loss < best_loss:\n\n                best_loss = valid_loss\n                oof[val_idx] = valid_preds\n                torch.save(model.state_dict(), mod_name)\n\n            elif(EARLY_STOP == True):\n\n                early_step += 1\n                if (early_step >= early_stopping_steps):\n                    break\n\n        #--------------------- PREDICTION---------------------\n        testdataset = TestDataset(x_test, transformer)\n        testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, len(target_cols))\n        \n        model.load_state_dict(torch.load(mod_name))\n        model.to(DEVICE)\n\n        predictions = np.zeros((len(test_), len(target_cols)))\n        predictions = inference_fn(model, testloader, DEVICE)\n        return oof, predictions\n\n    def run_k_fold(NFOLDS, seed):\n        oof = np.zeros((len(train), len(target_cols)))\n        predictions = np.zeros((len(test), len(target_cols)))\n\n        for fold in range(NFOLDS):\n            oof_, pred_ = run_training(fold, seed)\n\n            predictions += pred_ / NFOLDS\n            oof += oof_\n\n        return oof, predictions\n\n    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n    oof += oof_ / len(SEED)\n    predictions += predictions_ / len(SEED)\n    \n    oof_tmp = dp(oof)\n    oof_tmp = oof_tmp * len(SEED) / (SEED.index(seed)+1)\n    sc_dic[seed] = np.mean([log_loss(train[target_cols].iloc[:,i],oof_tmp[:,i]) for i in range(len(target_cols))])\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import log_loss\nprint(np.mean([log_loss(train[target_cols].iloc[:,i],oof[:,i]) for i in range(len(target_cols))]))\n\ntrain0[target_cols] = oof\ntest[target_cols] = predictions\n\n\nsub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\nsub.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}